# 1 订单系统相关场景

## 1.1  一个真实电商订单系统的整体架构、业务流程及负载情况

​	**订单系统核心业务：**

![image-20211224145132976](中间件专栏(RockerMq).assets/image-20211224145132976.png)

​	订单系统最核心的一个环节就出现了，就是要根据APP端传递过来的种种信息，完成订单的创建，此时需要在数据库中创建对应的订单记录，整个过程，就像下面这个图一样

![image-20211224145411880](中间件专栏(RockerMq).assets/image-20211224145411880.png)

**订单系统的非核心业务流程**

![image-20211224145448682](中间件专栏(RockerMq).assets/image-20211224145448682.png)

**订单系统的真实生产负载情况**

压力主要在两方面：

- 一方面是订单系统日益增长的数据量
- 一方面是在大促活动时每秒上万的访问压力

## 1.2 概括一下你们系统的架构设计、业务流程以及负载情况

OA系统、CRM系统、财务系统或者其他任何看起来很普通的系统，也许总共就几十个人用。

那你能不能思考一下，假设你的这个系统是一个SaaS云平台，要提供给几万个公司的百万用户去使用呢？

如果是这样，那你的系统必然会有很多的技术挑战，你可以去预估一下，当达到那个数量级之后，你的系统会有多大的数据量？多大的访问量？然后再去思考在这么大的数据量和访问量之下，现有的系统会有哪些技术难题？

接着你就可以思考，应该学习一些什么样的技术来解决这些问题？

## 1.3 系统面临的现实问题：下订单的同时还要发券、发红包、Push推送，性能太差

**系统压力越来越大到底指的是什么意思**

![image-20211224145945574](中间件专栏(RockerMq).assets/image-20211224145945574.png)

​	用户的使用习惯直接决定了他们使用我们APP的频率、时间段和时长，一般每隔几天用一次我们的APP？每次使用一般在什么时间段？每次使用多长时间？

​	这些东西都要通过对用户的分析得出来

**根据线上统计数据推算出系统的负载**

​	根据线上系统的接口统计数据来看，晚上购物最活跃的时候，订单系统下单最顶点的高峰时段每秒会有超过2000的请求，这就是订单系统的最高负载。其他时候都比这个负载会低不少。

**为什么系统的压力会越来越大**

​	要明白什么是系统压力，就得明白你的系统线上部署的机器情况和使用的数据库的机器情况

​	而且作为一个合格的互联网行业的Java工程师，要对各种机器配置大致能抗下的并发量有一个基本的了解

​	4核8G的机器一般每秒钟抗几百请求都没问题，现在才每秒两三百请求，CPU资源使用率都不超过50%。

​	可以说8台4核8G的机器，每台机器每秒高峰期两三百请求是很轻松的。

​	然后数据库服务器因为用的是16核32G的配置，因此之前压测的时候知道他即使每秒上万请求也能做到，只不过那个已经是他的极限了，会导致数据库服务器的CPU、磁盘、网络、IO、内存的使用率几乎达到极限。

​	但是一般来说在每秒四五千的请求的话，这样的数据库服务器是没什么问题的，何况经过线上监控统计，现在数据库服务器在高峰期的每秒请求量也就是三四千的样子，因此基本上还没什么大问题

![image-20211224150107260](中间件专栏(RockerMq).assets/image-20211224150107260.png)

**如果系统压力越来越大会怎么样**

![image-20211224150325837](中间件专栏(RockerMq).assets/image-20211224150325837.png)

​	有时候在高峰期负载压力很高的时候，如果数据库的负载较高，会导致数据库服务器的磁盘、IO、CPU的负载都很高，会导致数据库上执行的SQL语句性能有所下降。

​	因此在高峰期的时候，有的时候甚至需要几秒钟的时间完成上述几个步骤。

​	首先针对步骤8里的子步骤过多，速度过慢，让用户支付之后等待时间过长的问题，就是**订单系统第一个需要解决的问题**！

## 4.4 系统的核心流程性能如何？有没有哪个环节拖慢了速度

​	根据系统的负载情况，我们要搞明白线上系统部署的机器情况和数据库的机器情况，每台机器的配置情况，然后想想到底每台机器可以抗多大的访问量。得出当前系统的整体压力。

接着要思考，在当前这样的系统压力下：

- 系统的核心业务流程性能如何？
- 核心流程的每个步骤要耗费多长时间？
- 现在核心流程的性能你满意吗？是否还有优化的空间？
- 在系统高峰期的时候，机器和数据库负载很高，是否对核心流程的性能有影响？
- 如果有影响的话，会有多大的影响？

我的系统总共就几十个人用，根本没有压力可言，这怎么办？

那你就想，你的这个系统做一个SaaS云平台的模式，提供给几万个公司，百万用户使用，不就可以了？你要自己去模拟这个场景。

然后，你按照文中的思路去推算出系统高峰期的负载，以及你的线上系统的机器的压力，到底要部署多少机器去满足这个压力。

## 4.5 系统面临的现实问题：订单退款时经常流程失败，无法完成退款

**复杂的订单支付流程**

![image-20211224152030062](中间件专栏(RockerMq).assets/image-20211224152030062.png)

**对订单进行退款时需要干些什么**

本质上订单退款应该是一个订单支付的逆向过程，也就是说他应该做如下一些事：

- 重新给商品增加库存
- 更新订单状态为“已完成”
- 减少你的积分
- 收回你的优惠券和红包
- 发送Push告诉你退款完成了
- 通知仓储系统取消发货

最重要的是，需要通过第三方支付系统把钱重新退还给你。

而且如果电商平台都已经给你发货了，你才申请退款，实际上你还得把收到的商品给人家快递回去，等他们收到了商品再把钱退还给你。

这是退款的流程图

![image-20211224152554613](中间件专栏(RockerMq).assets/image-20211224152554613.png)

**PS:退款的最大问题：第三方支付系统如果退款失败怎么办(后续??)**

**如果用户下单后一直不付款怎么办**

​	此时订单的状态“待支付”，而且只要你下了订单，你订单里涉及到的商品，都会有对应的锁定库存的一个工作，相当于给你预先保留好这些商品。

​	我们的订单系统会启动一个后台线程，这个后台线程就是专门扫描数据库里那些待付款的订单。

​	如果发现超过24小时还没付款，就直接把订单状态改成“已关闭”了，释放掉锁定的那些商品库存。

![image-20211224152953406](中间件专栏(RockerMq).assets/image-20211224152953406.png)

## 4.6 你们系统出现过核心流程链路失败的情况吗

因为不管是什么系统，无论是一些管理信息系统，还是互联网系统，或者大数据系统，一定有一个核心的链路。

关键步骤失败了，这个时候会怎么样？如果某个步骤没有成功，是不是需要启动后台线程定时扫描进行补偿？

## 4.7 系统面临的现实问题：第三方客户系统的对接耦合性太高，经常出问题

**系统之间的耦合**

![image-20211224153823221](中间件专栏(RockerMq).assets/image-20211224153823221.png)

​	订单系统跟促销系统是强耦合的。因为促销系统任何一点接口修改，都会牵扯你围着他转，去配合他， 耗费你们订单团队的人力和时间，说明你们两个系统耦合在一起了。

​	要动一起动，要静一起静，这就是系统间的耦合。

​	订单系统不就跟仓储系统、第三方物流系统，全部耦合在一起了

​	他的性能突然降低，我们的系统性能就降低了，万一他接口突然调用失败，我们的这次操作也会失败，后续还要考虑重试机制

**PS:第三方系统，永远是不能完全信任的，他随时有可能出现意料之外的性能变差、接口失败的问题**

## 4.8 跟第三方系统对接过，有遇到什么问题

​	负责的系统是否跟某个第三方系统进行了耦合

​	系统跟第三方系统耦合了，是否遇到了性能上的问题？

​	比如你自己系统就只要20ms，结果第三方系统要200ms。

​	是否有稳定性的问题？比如第三方系统的接口有时候会超时、失败。

## 4.9 系统面临的现实问题：大数据团队需要订单数据，该怎么办

**大数据到底是干嘛的**

​	**所以每天如果有100万用户来访问你的APP，积累下来的一些浏览行为、访问行为、交易行为都是各种数据，这个数据量很大，所以你可以称之为“大数据”**

​	大数据团队:尽可能的搜集每天100万用户在你的APP上的各种行为数据

**几百行的大SQL直接查线上库的危害**

​	每次当有几十个几百行的大SQL同时运行在我们订单数据库里的时候，都会导致我们的数据库CPU负载很高，磁盘IO负载很高！

​	一旦我们的数据库负载很高，直接会导致我们的订单系统执行的一些增删改查的操作性能大幅度下降！

## 4.10 自己系统的数据，其他团队需要获取的

​	商品系统，即要对外提供商品数据访问的系统，需要大量的数据，也是需要库存数据、促销数据等等，此时也是需要进行跨系统的数据访问。

​	可以结合这种情况思考一下，在你们公司里，跨系统的数据访问是否存在？都是什么样的场景？

## 4.11 系统面临的现实问题：秒杀活动时数据库压力太大，该怎么缓解

**双11对一个订单系统到底有多大压力**

​	会执行多少条SQL在订单数据库上,一般你可以认为平均每个接口会执行2~3次的数据库操作

​	公司现在积累的注册用户已经千万级了，平时的日活用户都百万级，今年的双11参与活动的用户预计有可能会达到两三百万。

​	假设是这个量级的话，基本可以做一个设想，如果有200万用户参与双11活动，在双11购物最高峰的时候，肯定会比往年的高峰QPS高好几倍，预计有可能今年双11最高峰的时候，会达到每秒至少1万的QPS。

​	也就是说，光是系统被请求的QPS就会达到1万以上，那么系统请求数据库的QPS就会达到2万以上。仅仅凭借我们目前的数据库性能，是无论如何扛不住每秒2万请求的。

## 4.12 系统会不会遇到流量洪峰的场景，导致瞬时压力过大

​	各自的系统平时的QPS有多高

​	完全可以自己写一个简单的QPS统计框架，在你的各个接口被调用的时候，先执行这个QPS统计框架的代码。

​	然后在QPS统计框架里计算各个接口每秒被访问的次数，然后输出到你的日志文件里去即可。

​	当然，更好的方式是采用一些可视化的监控系统去观察你的系统的QPS。

​	接着建议大家去观察一下自己线上数据库的QPS，一般也都是基于一些可视化监控系统去看的

​	假设你的系统突然出现一阵流量洪峰，比如每秒QPS突然暴增100倍，甚至1000倍，此时你的系统能抗住吗？数据库能抗住吗？

## 4.13 一张思维导图给你梳理高并发订单系统面临的技术痛点

![image-20211224163549520](中间件专栏(RockerMq).assets/image-20211224163549520.png)



## 4.14 放大100倍压力，也要找出你系统的技术挑战

总结：

**第一**，先思考一下系统的核心业务流程，当然不是指那种查询之类的操作。所谓核心链路指的是对你的系统进行的数据更新的操作，这才是核心链路，因为查询操作一般来说不涉及复杂的业务逻辑，主要是对数据的展示。

对你的系统的核心链路分析一下，有哪些步骤，这些步骤各自的性能如何，综合起来让你的核心链路的性能如何？在这里是否有改进的空间？

**第二**，可以思考一下，在你的系统中，是否有类似后台线程定时补偿的逻辑？

比如订单时间未支付就要自动关闭它，你们系统里有没有那种后台线程，会定时扫描你的数据，对异常数据进行补偿、自动修复等操作的？

如果有的话，这种数据一般量有多大？如果没有，你可以思考一下，你们系统的核心数据是否需要类似的后台自动扫描机制？

**第三**，可以思考一下，在你的系统里有没有跟第三方系统进行耦合？就是一些核心流程里需要同步调用第三方系统进行查询、更新等操作，第三方系统是否对你的核心链路有性能和稳定性上的影响？

**第四**，可以思考一下，在你的核心链路中，是否存在那种关键步骤可能会失败的情况？万一失败了该怎么办？

**第五**，可以思考一下，平时是否存在其他系统需要获取你们数据的情况？他们是如何获取你们数据的？

是直接跑SQL从你们数据库里查询？或者是调用你们的接口来获取数据？是否存在这种情况？如果有，对你们有什么影响吗？

**第六**，系统是否存在流量洪峰的情况，有时候突然之间访问量增大好几倍，是否会对你们的系统产生无法承受的压力？

# 2 MQ选型及特点

## 2.1 解决订单系统诸多问题的核心技术：消息中间件到底是什么

**同步调用：**

​	用户发起一个请求，系统A收到请求，接着系统A必须立马去调用系统B，直到系统B返回了，系统A才能返回结果给用户，这种模式其实就是所谓的“同步调用”。

![image-20211230111130238](中间件专栏(RockerMq).assets/image-20211230111130238.png)

**依托消息中间件实现异步**

​	异步调用，意思就是系统A先干了自己的工作，然后想办法去通知了系统B。

​	但是系统B什么时候收到通知？什么时候去干自己的工作？这个系统A不管，不想管，也没法管，跟他就没关系了。

​	但是最终在正常下，系统B总会获取到这个通知，然后干自己该干的事儿。

![image-20211230111203993](中间件专栏(RockerMq).assets/image-20211230111203993.png)

**PS:消息中间件，其实就是一种系统，他自己也是独立部署的，然后让我们的两个系统之间通过发消息和收消息，来进行异步的调用，而不是仅仅局限于同步调用**

**消息中间件作用：**

​	**异步化提升性能，降低系统耦合，流量削峰**

​	MQ进行流量削峰的效果，**系统A发送过来的每秒1万请求是一个流量洪峰，然后MQ直接给扛下来了，都存储自己本地磁盘**，这个过程就是流量削峰的过程，瞬间把一个洪峰给削下来了，让系统B后续慢慢获取消息来处理。

**基于MQ优化系统：**

​	能不能提升你的核心链路的性能？能不能降低你系统跟其他系统的耦合度？能不能让你的系统应对流量洪峰？

## 2.2 Kafka、RabbitMQ 以及 RocketMQ 进行技术选型调研

**MQ选型对比**

- 业内常用的MQ有哪些？
- 每一种MQ各自的表现如何？
- 这些MQ在同等机器条件下，能抗多少QPS（每秒抗几千QPS还是几万QPS）？
- 性能有多高（发送一条消息给他要2ms还是20ms）？
- 可用性能不能得到保证（要是MQ部署的机器挂了怎么办）？
- 他们会不会丢失数据？
- 如果需要的话能否让他们进行线性的集群扩容（就是多加几台机器）？
- 消息中间件经常需要使用的一些功能他们都有吗（比如说延迟消息、事务消息、消息堆积、消息回溯、死信队列，等等）？
- 这些MQ在文档是否齐全？社区是否活跃？在行业内是否广泛运用？是用什么语言编写的？

**Kafka、RabbitMQ以及RocketMQ的调研对比**

​	**Kafka的优势和劣势**

​		首先**Kafka的吞吐量几乎是行业里最优秀的，在常规的机器配置下，一台机器可以达到每秒十几万的QPS**，相当的强悍。

​		Kafka性能也很高，基本**上发送消息给Kafka都是毫秒级的性能**。可用性也很高，**Kafka是可以支持集群部署的，其中部分机器宕机是可以继续运行的**。

​		但是Kafka比较为人诟病的一点，似乎是丢数据方面的问题，因为**Kafka收到消息之后会写入一个磁盘缓冲区里，并没有直接落地到物理磁盘上去**，所以要是**机器本身故障了，可能会导致磁盘缓冲区里的数据丢失**。

​		而且**Kafka**另外一个比较大的缺点，就是**功能相对单一**，主要是**支持发送消息给他，然后从里面消费消息，其他就没有什么额外的高级功能了。所以基于Kafka有限的功能，可能适用的场景并不是很多**。

​		因此综上所述，以及查阅了**Kafka技术在各大公司里的使用，基本行业里的一个标准，是把Kafka用在用户行为日志的采集和传输上，比如大数据团队要收集APP上用户的一些行为日志**，这种日志就是用Kafka来收集和传输的。

​		因为那种日志适当丢失数据是没有关系的，而且一般量特别大，要求吞吐量要高，一般就是收发消息，不需要太多的高级功能，所以Kafka是非常适合这种场景的。

​	**RabbitMQ的优势和历史**

​		再说RabbitMQ，在RocketMQ出现之前，国内大部分公司都从ActiveMQ切换到RabbitMQ来使用，包括很多一线互联网大厂，而且直到现在都有很多中小型公司在使用RabbitMQ。

​		**RabbitMQ的优势在于可以保证数据不丢失，也能保证高可用性，即集群部署的时候部分机器宕机可以继续运行，然后支持部分高级功能，比如说死信队列，消息重试之类的**，这些是他的优点。

​		但是他也有一些缺点，最为人诟病的，就是**RabbitMQ的吞吐量是比较低的，一般就是每秒几万的级别，所以如果遇到特别特别高并发的情况下，支撑起来是有点困难的**。

​		而且他进行**集群扩展的时候（也就是加机器部署），还比较麻烦**。

​		另外还有一个较为致命的缺陷，就是他的开**发语言是erlang，国内很少有精通erlang语言的工程师，因此也没办法去阅读他的源代码，甚至修改他的源代码**。

​		所以现在行业里的一个情况是，很多BAT等一线互联网大厂都切换到使用更加优秀的RocketMQ了，但是很多中小型公司觉得RabbitMQ基本可以满足自己的需求还在继续使用中，因为中小型公司并不需要特别高的吞吐量，RabbitMQ已经足以满足他们的需求了，而且也不需要部署特别大规模的集群，也没必要去阅读和修改RabbitMQ的源码。

​	**RocketMQ的优势和劣势**

​		RocketMQ是阿里开源的消息中间件，久经沙场，非常的靠谱。他几乎同时解决了Kafka和RabbitMQ的缺陷。

​		**RocketMQ的吞吐量也同样很高，单机可以达到10万QPS以上，而且可以保证高可用性，性能很高，而且支持通过配置保证数据绝对不丢失，可以部署大规模的集群，还支持各种高级的功能，比如说延迟消息、事务消息、消息回溯、死信队列、消息积压，等等**。

​		而**且RocketMQ是基于Java开发**的，符合国内大多数公司的技术栈，很容易就可以阅读他的源码，甚至是修改他的源码。

​		所以现在国内很多一线互联网大厂都切换为使用RocketMQ了，他们需要RocketMQ的高吞吐量，大规模集群部署能力，以及各种高阶的功能去支撑自己的各种业务场景，同时还可以根据自己的需求定制修改RocketMQ的源码。

​		RocketMQ是非常适合用在Java业务系统架构中的，因为他很高的性能表现，还有他的高阶功能的支持，可以让我们解决各种业务问题。

​		当然，RocketMQ也有一点美中不足的地方，就是经过我的调查发现，RocketMQ的官方文档相对简单一些，但是Kafka和RabbitMQ的官方文档就非常的全面和详细，这可能是RocketMQ目前唯一的缺点。

从架构原理上自己对比一下Kafka、RabbitMQ、RocketMQ

1. 他们都是如何集群化部署抗高并发的？
2. 他们对海量消息是如何分布式存储的？
3. 他们是如何实现主从多备份的高可用架构的？
4. 他们是如何实现集群路由让别人找到对应的机器发送消息和接收消息的？

## 2.3 RocketMQ 的架构原理和使用方式

**MQ如何集群化部署来支撑高并发访问**

​	RocketMQ是可以集群化部署的，可以部署在多台机器上，假设每台机器都能抗10万并发，然后你只要让几十万请求分散到多台机器上就可以了，让每台机器承受的QPS不超过10万

![image-20211230153802761](中间件专栏(RockerMq).assets/image-20211230153802761.png)

**MQ如果要存储海量消息应该怎么做**

​	本质上RocketMQ存储海量消息的机制就是分布式的存储

​	所谓分布式存储，就是把数据分散在多台机器上来存储，每台机器存储一部分消息，这样多台机器加起来就可以存储海量消息了

![image-20211230154928304](中间件专栏(RockerMq).assets/image-20211230154928304.png)

**高可用保障：万一Broker宕机了怎么办**

​	RocketMQ的解决思路是Broker主从架构以及多副本策略。

​	Master Broker收到消息之后会同步给Slave Broker，这样Slave Broker上就能有一模一样的一份副本数据！

​	如果任何一个Master Broker出现故障，还有一个Slave Broker上有一份数据副本，可以保证数据不丢失，还能继续对外提供服务，保证了MQ的可靠性和高可用性

![image-20211230160148745](中间件专栏(RockerMq).assets/image-20211230160148745.png)

**数据路由：怎么知道访问哪个Broker**

​	NameServer的概念，他也是独立部署在几台机器上的，然后所有的Broker都会把自己注册到NameServer上去，NameServer不就知道集群里有哪些Broker了

​	发送消息到Broker，会找NameServer去获取路由信息，就是集群里有哪些Broker等信息

​	如果系统要从Broker获取消息，也会找NameServer获取路由信息，去找到对应的Broker获取消息

![image-20211230160626422](中间件专栏(RockerMq).assets/image-20211230160626422.png)

# 3 RocketMq架构原理

## 3.1 消息中间件路由中心的架构原理是什么

**NameServer部署**

​	通常来说，NameServer一定会多机器部署，实现一个集群，起到高可用的效果，保证任何一台机器宕机，其他机器上的NameServer可以继续对外提供服务

**Broker是把自己的信息注册到哪个NameServer上去**

​	每个Broker启动都得向所有的NameServer进行注册

**系统如何从NameServer获取Broker信息**

​	RocketMQ中的生产者和消费者就是这样，**自己主动去NameServer拉取Broker信息的**

**Broker跟NameServer之间的心跳机制**

​	**Broker会每隔30s给所有的NameServer发送心跳**，告诉每个NameServer自己目前还活着

​	每次NameServer收到一个Broker的心跳，就可以更新一下他的最近一次心跳的时间

​	然后NameServer会每隔10s运行一个任务，去检查一下各个Broker的最近一次心跳时间，如果某个Broker超过120s都没发送心跳了，那么就认为这个Broker已经挂掉了。

![image-20211230172740604](中间件专栏(RockerMq).assets/image-20211230172740604.png)

## 3.2 要是没有这个路由中心，消息中间件可以正常运作么

**路由中心**

​	路由中心的角色需要去感知集群里所有的Broker节点，然后需要去配合生产者和消费者，让人家都能感知到集群里有哪些Broker，才能让各个系统跟MQ进行通信

​	Kafka的路由中心实际上是一个非常复杂、混乱的存在。他是由ZooKeeper以及某个作为Controller的Broker共同完成的。

​	RabbitMQ的话自己本身就是由集群每个节点同时扮演了路由中心的角色。

​	RocketMQ是把路由中心抽离出来作为一个独立的NameServer角色运行的，因此可以说在路由中心这块，他的架构设计是最清晰明了的。

**NameServer集群整体都故障了，失去了这个NameServer集群之后：**

- RocketMQ还能正常运行吗？
- 生产者还能发送消息到Broker吗？
- 消费者还能从Broker拉取消息吗？

## 3.3 Broker的主从架构原理是什么

**Master Broker是如何将消息同步给Slave Broker的**

​	RocketMQ的Master-Slave模式采取的是Slave Broker不停的发送请求到Master Broker去拉取消息

​	RocketMQ自身的Master-Slave模式采取的是**Pull模式**拉取消息

![image-20220104110153725](中间件专栏(RockerMq).assets/image-20220104110153725.png)

**RocketMQ 实现读写分离了吗**

​	问题：作为消费者的系统在获取消息的时候，是从Master Broker获取的？还是从Slave Broker获取的？

​	回答：**有可能从Master Broker获取消息，也有可能从Slave Broker获取消息**

​	1 消费者的系统在获取消息的时候会先发送请求到Master Broker上去，请求获取一批消息，此时Master Broker是会返回一批消息给消费者系统的

​	2 Master Broker在返回消息给消费者系统的时候，会根据当时Master Broker的负载情况和Slave Broker的同步情况，向消费者系统建议下一次拉取消息的时候是从Master Broker拉取还是从Slave Broker拉取

示例：

​	要是这个时候Master Broker负载很重，本身要抗10万写并发了，你还要从他这里拉取消息，给他加重负担，那肯定是不合适的。

​	所以此时Master Broker就会建议你从Slave Broker去拉取消息。

​	或者举另外一个例子，本身这个时候Master Broker上都已经写入了100万条数据了，结果Slave Broke不知道啥原因，同步的特别慢，才同步了96万条数据，落后了整整4万条消息的同步，这个时候你作为消费者系统可能都获取到96万条数据了，那么下次还是只能从Master Broker去拉取消息

总结：

​	所以在写入消息的时候，通常来说肯定是选择Master Broker去写入的

​	但是在拉取消息的时候，有可能从Master Broker获取，也可能从Slave Broker去获取，一切都根据当时的情况来定。

![image-20220104110507602](中间件专栏(RockerMq).assets/image-20220104110507602.png)

 **Broke挂掉的影响**

​	**Slave Broke挂掉了**

​		**有一点影响，但是影响不太大。少了Slave Broker，会导致所有读写压力都集中在Master Broker上**

​	**Master Broker挂掉了**

​		在RocketMQ 4.5版本之前，都是用Slave Broker同步数据，尽量保证数据不丢失，但是一旦Master故障了，Slave是没法自动切换成Master的。

​		所以在这种情况下，如果Master Broker宕机了，这时就得手动做一些运维操作，把Slave Broker重新修改一些配置，重启机器给调整为Master Broker，这是有点麻烦的，而且会导致中间一段时间不可用

**基于Dledger实现RocketMQ高可用自动切换**

​	**基于Raft协议实现的一个机制**

​	**把Dledger融入RocketMQ之后，就可以让一个Master Broker对应多个Slave Broker，也就是说一份数据可以有多份副本**，比如一个Master Broker对应两个Slave Broker

​	一旦**Master Broker宕机了，就可以在多个副本，也就是多个Slave中，通过Dledger技术和Raft协议算法进行leader选举**，直接将一个Slave Broker选举为新的Master Broker，然后这个新的Master Broker就可以对外提供服务了。

​	整个过程也许只要10秒或者几十秒的时间就可以完成，这样的话，就可以实现Master Broker挂掉之后，自动从多个Slave Broker中选举出来一个新的Master Broker，继续对外服务，一切都是自动的



![image-20220104110924181](中间件专栏(RockerMq).assets/image-20220104110924181.png)

问题：

- 假设如果没有RocketMQ 4.5新版本引入的Dledger技术，仅仅是靠之前的Master-Slave主从同步机制，那么在Master崩溃的时候，可能会造成多长时间的系统不可用？这个时候如何能够尽快的恢复集群运行？依赖手工运维的话，如何能尽快的去完成这个运维操作？

- 在RocketMQ 4.5之后引入了Dledger技术可以做到自动选举新的Master，那么在Master崩溃一直到新的Master被选举出来的这个过程中，你觉得对于使用MQ的系统而言，会处于一个什么样的状态呢？

- 希望大家去研究一下Kafka和RabbitMQ的多副本和高可用机制，Kafka是如何在集群里维护多个副本的？出现故障的时候能否实现自动切换？RabbitMQ是如何在集群里维护多个数据副本的？出现故障的时候能否实现自动切换？

- 既然有主从同步机制，那么有没有主从数据不一致的问题？Slave永远落后Master一些数据，这就是主从不一致。那么这种不一致有没有什么问题？有办法保证主从数据强制一致吗？这样做又会有什么缺点呢？

# 4 RocketMq落地及设计

## 4.1 设计一套高可用的消息中间件生产部署架构

**设计：**

​	**1 NameServer集群化部署，保证高可用性**

​	**2 基于Dledger的Broker主从架构部署**

​	**3 使用MQ的系统都要多机器集群部署**

​	**4 整体架构：高可用、高并发、海量消息、可伸缩**

**Broker是如何跟NameServer进行通信的**

​	**基本概念：**

​	**Broker会每隔30秒发送心跳到所有的NameServer上去，然后每个NameServer都会每隔10s检查一次有没有哪个Broker超过120s没发送心跳的，如果有，就认为那个Broker已经宕机了，从路由信息里要摘除这个Broker**

​	**流程：**

​	Broker会跟每个NameServer都建立一个TCP长连接，然后定时通过TCP长连接发送心跳请求过去

​	各个NameServer就是通过跟Broker建立好的长连接不断收到心跳包，然后定时检查Broker有没有120s都没发送心跳包，来判定集群里各个Broker到底挂掉了没有

**MQ的核心数据模型：Topic**

​	**基本概念：**

​	系统如果要往MQ里写入消息或者获取消息，首先得创建一些Topic，作为数据集合存放不同类型的消息，比如说订单Topic，商品Topic，等等

​	**分布式存储：**

​	可以在创建Topic的时候指定让他里面的数据分散存储在多台Broker机器上，比如一个Topic里有1000万条数据，此时有2台Broker，那么就可以让每台Broker上都放500万条数据

​	每个Broke在进行定时的心跳汇报给NameServer的时候，都会告诉NameServer自己当前的数据情况，比如有哪些Topic的哪些数据在自己这里，这些信息都是属于路由信息的一部分

**生产者系统是如何将消息发送到Broker的**

​	**流程：**

​	发送消息之前，得先有一个Topic，然后在发送消息的时候你得指定你要发送到哪个Topic里面去

​	知道你要发送的Topic，那么就可以跟NameServer建立一个TCP长连接，然后定时从他那里拉取到最新的路由信息，包括集群里有哪些Broker，集群里有哪些Topic，每个Topic都存储在哪些Broker上

​	生产者系统自然就**可以通过路由信息找到自己要投递消息的Topic分布在哪几台Broker上**，此时可以**根据负载均衡算法，从里面选择一台Broke机器出来**，比如round robine轮询算法，或者是hash算法，都可以

​	选择一台Broker之后，就可以跟那个**Broker也建立一个TCP长连接，然后通过长连接向Broker发送消息**即可

​	Broker收到消息之后就会存储在自己本地磁盘里去

​	**PS:生产者一定是投递消息到Master Broker的，然后Master Broker会同步数据给他的Slave Brokers，实现一份数据多份副本，保证Master故障的时候数据不丢失，而且可以自动把Slave切换为Master提供服务**

**消费者是如何从Broker上拉取消息的**

​	会**跟NameServer建立长连接，然后拉取路由信息**，接着找到自己要获取消息的**Topic在哪几台Broker上，就可以跟Broker建立长连接，从里面拉取消息了**

​	消费者系统可能会从Master Broker拉取消息，也可能从Slave Broker拉取消息，都有可能，一切都看具体情况。

![image-20220105143409318](中间件专栏(RockerMq).assets/image-20220105143409318.png)

**问题：**

- 在你们公司里有用MQ吗？
- 如果有的话是什么MQ？
- 你们的MQ在生产环境的部署架构是怎么做的？
- 路由中心、MQ集群、生产者和消费者分别是怎么部署的？为什么要那样部署？
- 那样部署可以实现高并发、海量消息、高可用和线性可伸缩吗？
- RabbitMQ和Kafka他们两个是如何实现生产架构部署，来支撑高并发、海量消息、高可用和可伸缩的呢？他们能实现这些吗？

