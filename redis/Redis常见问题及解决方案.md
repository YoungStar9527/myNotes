# 1 高并发场景下的缓存+数据库双写不一致问题分析与解决方案

**PS:以下问题及解决方案都是基于Cacae Aside Pattern模式**

## 1.1 初级的缓存不一致问题及解决方案

​	**问题：**先修改数据库，再删除缓存，如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据出现不一致

​	**解决思路：**先删除缓存，再修改数据库，如果删除缓存成功了，修改数据库失败了，那么数据库是旧数据，缓存中是空的，那么数据不会不一致，因为都读的时候缓存没有，则数据库中的旧数据更新到缓存中

## 1.2 比较复杂的数据不一致问题分析

### 1.2.1 并发场景下的缓存不一致问题

**问题：**

​	数据发生了变更，先删除缓存，然后去修改数据库，此时还没修改

​	这个时候一个读请求过滤，发现缓存空了，去查询数据库，查到了修改前的旧数据，放到了缓存中

​	数据变更的程序完成了数据库的修改，此时又出现数据库和缓存中数据不一样了

**解决方案：**

​	更新数据的时候，根据数据的唯一标识，将操作路由之后，发送到一个JVM内部的队列中

​	读取数据的时候，如果发现数据不在缓存中，那么将重新读取数据+更新缓存的操作，根据唯一标识路由之后，也发送同一个JVM内部的队列中

​	一个队列对应一个工作线程

​	每个工作线程串行拿到对应的操作，然后一条一条的执行

​	这样的话，一个数据变更的操作，先执行，删除缓存，然后再去更新数据库，但是还没完成更新

​	此时如果一个读请求过来，读到了空的缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成

**优化点：**

​	一个队列中多个读请求(更新缓存)串在一起是没意义的，可以做过滤。如果发现队列中已经有一个读请求(更新缓存)了，那么就不放这个操作进去了，直接等待前面的更新操作请求完成即可,后续等待的读请求就直接能读取缓存中的数据了。

​	设置一个等待的时间范围，在时间范围内轮询发现可以取到值了就直接返回。超过请求时长可以返回旧值(查数据库)/抛出异常(看业务需要)。

**图示：**

![image-20210529154908241](Redis常见问题及解决方案.assets/image-20210529154908241.png)

### 1.2.2 高并发场景，该方案应该注意的问题

**1 风险点-读请求长时间阻塞/写操作较多：**

​	可能数据更新很频繁。导致队列积压了大量更新操作，然后读请求大量超时，导致大量请求直接走数据库/异常，真实场景一定需要通过模拟真实的测试，看看更新数据的频率是否能支持。

**优化点：**

​	如果更新操作比较频繁，一个队列积压多个商品库存的更新操作。可以选择部署多个服务，每个服务分摊一些数据的更新操作。

**服务的预估：**

​	单机器：20个内存队列，每个队列可能积压5个写操作(100写QPS)，假如一个写操作20ms完成，20*5=100，读操作等待100ms，还是可以接受的

​	如果写QPS扩大10倍，那么久扩容机器，扩容10倍机器，10台机器，每个机器20个队列

**2 风险点-读请求并发量过高**

​	这里还必须做好压力测试，确保恰巧碰上上述情况的时候。还有一个风险，就是突然间大量读请求会在几十毫秒的延时,在服务上等待，看服务能不能抗的住，需要多少机器才能抗住大的极项情况的峰值

**优化点：**

​	做好读和写比例的优化测试，按照1:99的比例，每秒5万的读QPS,可能只有500次更新操作。每个更新操作可能影响1:1,1:2,1:3的读操作500*3也就是影响1000+的读操作，按照分队列的方案每个读请求等待200ms左右返回都是ok的

**3 风险点-热点商品的路由问题，导致请求的倾斜**

​	万一某个商品的读写请求特别高，全部打到相同的机器的相同的队列里面去了，可能造成某台机器的压力过大

​	就是说，因为只有在商品数据更新的时候才会清空缓存，然后才会导致读写并发，所以更新频率不是太高的话，这个问题的影响并不是特别大但是的确可能某些机器的负载会高一些

**优化点：**

​	评估实际业务，根据热点商品调整资源倾斜，热点商品多分配队列/机器，及服务器性能等操作

## 1.3 多服务实例部署的请求路由

​	可能这个服务部署了多个实例，那么必须保证说，执行数据更新操作，以及执行缓存更新操作的请求，都通过nginx服务器路由到相同的服务实例上

![image-20210529150706128](Redis常见问题及解决方案.assets/image-20210529150706128.png)

## **1.4 EhCache**

​	EhCache 是一个纯Java的进程内缓存框架，具有快速、精干等特点，是Hibernate中默认CacheProvider。Ehcache是一种广泛使用的开源Java分布式缓存。主要面向通用缓存,Java EE和轻量级容器。它具有内存和磁盘存储，缓存加载器,缓存扩展,缓存异常处理程序,一个gzip缓存servlet过滤器,支持REST和SOAP api等特点。

　　Spring 提供了对缓存功能的抽象：即允许绑定不同的缓存解决方案（如Ehcache），但本身不直接提供缓存功能的实现。它支持注解方式使用缓存，非常方便。

引用：https://www.cnblogs.com/myseries/p/11370109.html

# 2 缓存雪崩、缓存穿透、缓存击穿

## 2.1 缓存雪崩

### 2.1.1 缓存雪崩出现的情况及原因

​	缓存雪崩这种场景，缓存架构中非常重要的一个环节，应对缓存雪崩的解决方案，避免缓存雪崩的时候，造成整个系统崩溃，带来巨大的经济损失

​	**1、redis集群彻底雪崩**

​	2、缓存服务大量对redis的请求hang住，占用资源

​	3、缓存服务大量的请求打到源头服务去查询mysql，直接打死mysql

​	4、源头服务因为mysql被打死也崩溃，对源服务的请求也hang住，占用资源

​	5、缓存服务大量的资源全部耗费在访问redis和源服务无果，最后自己被拖死，无法提供服务

​	6、nginx无法访问缓存服务，redis和源服务，只能基于本地缓存提供服务，但是缓存过期后，没有数据提供

​	7、网站崩溃

![image-20210529163921653](Redis常见问题及解决方案.assets/image-20210529163921653.png)

​	redis集群在什么情况会彻底崩溃，redis集群自身的bug/redis集群机房断电 都可能导致redis集群彻底崩溃

**真实案例：**

​	行业里真实的缓存雪崩的经验和教训

​	某电商，之前就是出现过，整个缓存的集群彻底崩溃了，因为主要是集群本身的bug，导致自己把自己给弄死了，虽然当时也是部署了双机房的，但是还是死了

​	电商大量的，几乎所有的应用都是基于那个缓存集群去开发的

​	导致各种服务的线程资源全部被耗尽，然后用在了访问那个缓存集群时的等待、超时和报错上了

​	然后导致各种服务就没有资源对外提供服务

​	然后各种降级措施也没做好，直接就是整体系统的全盘崩溃

​	导致网站就没法对外出售商品，导致了很大数额的经济的损失

**扩展：**

​	需要对技术有高要求的话需要多学，多思考一些各种场景下的缓存架构，用来解决各种各样的问题

​	自己做系统架构设计的时候，需要考虑各种高并发场景下可能出现的问题，数据不一致，热点缓存，重建并发冲突，缓存雪崩，缓存穿透，缓存击穿，架构设计考虑的到位，稳定性就有保障，真正发生故障的时候能减少损失

### 2.1.2 缓存雪崩的解决方案

​	相对来说，考虑比较完善的一套方案，分为事前，事中，事后三个层次去思考怎么应对缓存雪崩的场景

**事前：**

​	发生缓存雪崩之前，事情之前，怎么去避免redis彻底挂掉

​	redis本身的高可用性，复制，主从架构，操作主节点，读写，数据同步到从节点，一旦主节点挂掉，从节点跟上

​	双机房部署，一套redis cluster，部分机器在一个机房，另一部分机器在另外一个机房

​	还有一种部署方式，两套redis cluster，两套redis cluster之间做一个数据的同步，redis集群是可以搭建成树状的结构的一旦说单个机房出了故障，至少说另外一个机房还能有些redis实例提供服务

**事中：**

redis cluster已经彻底崩溃了，已经开始大量的访问无法访问到redis了

(1) ehcache本地缓存
	所做的多级缓存架构的作用上了，ehcache的缓存，应对零散的redis中数据被清除掉的现象，另外一个主要是预防redis彻底崩溃

​	多台机器上部署的缓存服务实例的内存中，还有一套ehcache的缓存

​	ehcache的缓存还能支撑一阵

(2) 对redis访问的资源隔离

(3）对源服务访问的限流以及资源隔离（hystrix熔断/隔离）



![image-20210529170522800](Redis常见问题及解决方案.assets/image-20210529170522800.png)

**事后：**

(1) redis数据可以恢复，做了备份，redis数据备份和恢复，redis重新启动起来

(2) redis数据彻底丢失了，或者数据过旧，快速缓存预热(热点请求的数据先入缓存)，redis重新启动起来

redis对外提供服务

​	缓存服务里，熔断策略，自动可以恢复，half-open，发现redis可以访问了，自动恢复了，自动就继续去访问redis了

​	基于hystrix的高可用服务这块技术，缓存服务去设计成高可用的架构

​	缓存架构应对高并发下的缓存雪崩的解决方案，基于hystrix去做缓存服务的保护

**基于sentinel的降级机制**

​	资源隔离，避免说redis访问频繁失败，或者频繁超时的时候，耗尽大量的tomcat容器的资源去hang在redis的访问上

​	限定只有一部分线程资源可以用来访问redis

​	如果redis集群彻底崩溃了，这个时候，可能command对redis的访问大量的报错和timeout超时，熔断（短路)

​	**降级机制，fallback**

​	**fail silent模式**，fallback里面直接返回一个空值，比如一个null，最简单了

​	在外面调用redis的代码(CacheService类)，是感知不到redis的访问异常的，只要你把timeout、熔断、熔断恢复、降级，都做好了

​	可能会出现的情况是，当redis集群崩溃的时候，CacheService获取到的是大量的null空值

​	根据这个null空值，我们还可以去做多级缓存的降级访问，nginx本地缓存，redis分布式集群缓存，ehcache本地缓存，CacheController(代码访问redis为Null，就去ehcache本地缓存去找)
