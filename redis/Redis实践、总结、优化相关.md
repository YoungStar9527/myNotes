# 1 常见问题的优化

## 1.1、fork耗时导致高并发请求延时

​	RDB和AOF的时候，其实会有生成RDB快照，AOF rewrite，耗费磁盘Io的过程，主进程fork子进程

​	fork的时候，子进程是需要拷贝父进程的空间内存页表的，也是会耗费一定的时间的

​	一般来说，如果父进程内存有1个G的数据，那么fork可能会耗费在2ms左右，如果是10G~30G，那么就会耗费20 *10，甚至20 * 30，也就是几百毫秒的时间

​	info stats中的latest_fork_usec，可以看到最近一次form的时长

​	redis单机QPS一般在几万，fork可能一下子就会拖慢几万条操作的请求时长，从几毫秒变成1秒

**优化思路**

​	fork耗时跟redis主进程的内存有关系，一般控制redis的内存在10GB以内，slave -> master，全量复制

## 1.2、AOF的阻塞问题

​	redis将数据写入AOF缓冲区，单独开一个现场做fsync操作，每秒一次

​	但是redis主线程会检查两次fsync的时间，如果距离上次fsync时间超过了2秒，那么写请求就会阻塞everysec，最多丢失2秒的数据

​	一旦fsync超过2秒的延时，整个redis就被拖慢

**优化思路**

​	优化硬盘写入速度，建议采用ssD，不要用普通的机械硬盘，SD，大幅度提升磁盘读写的速度

## 1.3、主从复制延迟问题

​	主从复制可能会超时严重，这个时候需要良好的监控和报警机制

​	在info replication中，可以看到master和slave复制的offset，做一个差值就可以看到对应的延迟量如果延迟过多，那么就进行报警

## 1.4、主从复制风暴问题

​	如果一下子让多个slave从master去执行全量复制，一份大的rdb同时发送到多个slave，会导致网络带宽被严重占用如果一个master真的要挂载多个slave，那尽量用**树状结构(slave下再挂slave)**，不要用**星型结构(所有slave都挂载master上)**

## 1.5、vm.overcommit _memory

0:检查有没有足够内存,没有的话申请内存失败

1:允许使用内存直到用完为止

2:内存地址空间不能超过swap + 50%

如果是0的话，可能导致类似fork等操作执行失败，申请不到足够的内存空间

```shell
cat /proc/sys/vm/overcommit_memory
echo "vm.overcommit_memory-1" >> letc/sysctl.conf
sysctl vm.overcommit _memory=1 T
```

## 1.6、swapiness

cat /proc/version，查看linux内核版本

如果linux内核版本<3.5，那么swapiness设置为0，这样系统宁愿swap也不会oom killer（杀掉进程)

如果linux内核版本>=3.5，那么swapiness设置为1，这样系统宁愿swap也不会oom killer

保证redis不会被杀掉

```shell
echo 0 > /proc/sys/vm/swappiness
echo vm.swapiness=0  /etc/sysctl.conf
```

## 1.7、最大打开文件句柄

```shell
ulimit -n 10032 10032
#不同liunx版本打开句柄命令有一点的区别
```

## 1.8、tcp backlog

```shell
cat /proc/sys/net/core/somaxconn
echo 511 > /proc/sys/net/core/somaxconn
```

# 2 redis解决的问题

​	redis;持久化、复制(主从架构)、哨兵《高可用，主备切换)、redis cluster(海量数据+横向扩容+高可用/主备切换)

​	持久化。高可用的一部分，在发生redis集群灾难的情况下（比如说部分master+slave全部死掉了)，如何快速进行数据恢复，快速实现服务可用，才能实现整个系统的高可用

​	复制:主从架构，master -) slave复制，读写分离的架构，写master，读slave，横向扩容slave支撑更高的读吞吐，读高并发，10万，20万，30万，上百万，QPS，横向扩容

​	哨兵:高可用，主从架构，在master故障的时候，快速将slave切换成master，实现快速的灾难恢复，实现高可用性

​	**redis cluster**:多master读写，数据分布式的存储，横向扩容，水平扩容，快速支撑高达的数据量+更高的读写0PS，自动进行master -〉 slave的主备切换,高可用。

​	让底层的缓存系统，redis，实现能够任意水平扩容，支撑海量数据(1T+，几十T，10G * 600 redis =
6T)，支撑很高的读写QPS (redis单机在几万QPS， 10台，几十万QPS)，高可用性（给我们每个redis实例都做好A0F+和RDB的备份策略+容灾策略，slave -master主备切换 1T+海量数据、10万+读写QPs、99.99%高可用性

# 3 多级缓存

## 3.1 三级缓存

​	**采用三级缓存:nginx本地缓存+redis分布式缓存+tomcat堆缓存的多级缓存架构**

​	**nginx本地缓存**，抗的是热数据的高并发访问，一般来说，商品的购买总是有热点的，比如每天购买iphone、nike、海尔等知名品牌的东西的人，总是比较多的

​	这些热数据，利用nginx本地缓存，由于经常被访问，所以可以被锁定在nginx的本地缓存内

​	大量的热数据的访问，就是经常会访问的那些数据，就会被保留在nginx本地缓存内，那么对这些热数据的大量访问，就直接走nginx就可以

​	那么大量的访问，直接就可以走到nginx就行了，不需要走后续的各种网络开销了

​	**redis分布式大规模缓存**，抗的是很高的离散访问，支撑海量的数据，高并发的访问，高可用的服务

​	redis缓存最大量的数据，最完整的数据和缓存，1T+数据;支撑高并发的访问，oPs最高到几十万;可用性，非常好，提供非常稳定的服务

​	nginx本地内存有限，也就能cache住部分热数据，除了各种iphone、nike等热数据，其他相对不那么热的数据，可能流量会经常走到redis那里

​	利用redis cluster的多master写入，横向扩容，1T+以上海量数据支持，几十万的读写OPS，99.99%高可用性，那么就可以抗住大量的离散访问请求

​	**tomcat jvm堆内存缓存**，主要是抗redis大规模灾难的，如果redis出现了大规模的宕机，导致ngimx大量流量直接涌入数据生产服务，那么最后的tomcat堆内存缓存至少可以缓冲一下，不至于mysql直接裸奔

​	同时tomcat jvm堆内存缓存，也可以抗住redis没有cache住的最后那少量的部分缓存

![image-20210527075657707](Redis实践、总结、优化相关.assets/image-20210527075657707.png)

**综合使用:**

​	nginx+lua脚本做页面动态生成的工作，每次请求过来，优先从nginx本地缓存中提取各种数据，结合页面模板，生成需要的页面

​	如果nginx本地缓存过期了，那么就从nginx到redis中去拉取数据，更新到nginx本地

​	如果redis中也被LRU算法清理掉了，那么就从nginx走http接口到后端的服务中拉取数据，数据生产服务中，现在本地tomcat里的jym堆缓存中找，ehcache,如果有被LRU清理掉了，那么久重新发送

​	请求到源头的服务中去拉取数据，然后再次更新tomcat堆内存缓存+redis缓存，并返回数据给nginx，nginx缓存到本地

## 3.2 相关样例

​	**时效性要求非常高的数据:**库存
​	一般来说，显示的库存，都是时效性要求会相对高一些，因为随着商品的不断的交易，库存会不断的变化，当然，我们就希望当库存变化的时候，尽可能更快将库存显示到页面上去，而不是说等了很长时间，库存才反应到页面上去

​	**时效性要求不高的数据:**商品的基本信息（名称、颜色、版本、规格参数，等等)

​	时效性要求不高的数据，就还好，比如说你现在改变了商品的名称，稍微晚个几分钟反应到商品页面上，也还能接受

# 4 Cache Aside Pattern缓存

## 4.1 基本模式

最经典的缓存+数据库读写的模式，cache aside pattern1、Cache Aside Pattern

​	(1) 读的时候，先读缓存，缓存没有的话，那么就读数据库，然后取出数据后放入缓存，同时返回响应

​	(2）更新的时候，先删除缓存，然后再更新数据库

## 4.2、为什么是删除缓存，而不是更新缓存呢?

​	原因很简单，很多时候，复杂点的缓存的场景，因为缓存有的时候，不简单是数据库中直接取出来的值

​	商品详情页的系统，修改摩存，只是修改了某个表的某些字段，但是要真正把这个影响的最终的库存计算出来，可能还需要从其他表查询一些数据，然后进行一些复杂的运算，才能最终计算出现在最新的库存是多少，然后才能将库存更新到缓存中去

​	比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据，并进行运算，才能计算出缓存最新的值的

​	更新缓存的代价是很高的

​	是不是说，每次修改数据库的时候，都一定要将其对应的缓存去跟新一份﹖也许有的场景是这样的，但是对于比较复杂的缓存数据计算的场景，就不是这样了

​	如果你频繁修改一个缓存涉及的多个表，那么这个缓存会被频繁的更新，频繁的更新缓存

​	但是问题在于，这个缓存到底会不会被频繁访问到? ??

​	举个例子，一个缓存涉及的表的字段，在1分钟内就修改了20次。或者是100次，那么缓存跟新20次，1次;但是这个缓存在1分钟内就被读取了1次，有大量的冷数据

​	28法则，黄金法则，20%的数据，占用了80%的访问量

​	实际上，如果你只是删除缓存的话，那么1分钟内，这个缓存不过就重新计算一次而已，开销大幅度降低

​	每次数据过来，就只是删除缓存。然后修改数据库，如果这个缓存，在1分钟内只是被访问了1次，那么只有那1次，缓存是要被重新计算的，用缓存才去算缓存

​	其实删除缓存，而不是更新缓存，就是一个lazy计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算

​	mybatis，hibernate，懒加载，思想